<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - ompi.info - ompi/runtime/ompi_mpi_init.c</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">ompi/runtime</a> - ompi_mpi_init.c<span style="font-size: 80%;"> (source / <a href="ompi_mpi_init.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">ompi.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">111</td>
            <td class="headerCovTableEntry">237</td>
            <td class="headerCovTableEntryLo">46.8 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2015-07-30 14:35:26</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">3</td>
            <td class="headerCovTableEntry">5</td>
            <td class="headerCovTableEntryLo">60.0 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */</a>
<span class="lineNum">       2 </span>            : /*
<span class="lineNum">       3 </span>            :  * Copyright (c) 2004-2010 The Trustees of Indiana University and Indiana
<span class="lineNum">       4 </span>            :  *                         University Research and Technology
<span class="lineNum">       5 </span>            :  *                         Corporation.  All rights reserved.
<span class="lineNum">       6 </span>            :  * Copyright (c) 2004-2014 The University of Tennessee and The University
<span class="lineNum">       7 </span>            :  *                         of Tennessee Research Foundation.  All rights
<span class="lineNum">       8 </span>            :  *                         reserved.
<span class="lineNum">       9 </span>            :  * Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,
<span class="lineNum">      10 </span>            :  *                         University of Stuttgart.  All rights reserved.
<span class="lineNum">      11 </span>            :  * Copyright (c) 2004-2005 The Regents of the University of California.
<span class="lineNum">      12 </span>            :  *                         All rights reserved.
<span class="lineNum">      13 </span>            :  * Copyright (c) 2006-2015 Cisco Systems, Inc.  All rights reserved.
<span class="lineNum">      14 </span>            :  * Copyright (c) 2006-2015 Los Alamos National Security, LLC.  All rights
<span class="lineNum">      15 </span>            :  *                         reserved.
<span class="lineNum">      16 </span>            :  * Copyright (c) 2006-2009 University of Houston. All rights reserved.
<span class="lineNum">      17 </span>            :  * Copyright (c) 2008-2009 Sun Microsystems, Inc.  All rights reserved.
<span class="lineNum">      18 </span>            :  * Copyright (c) 2011      Sandia National Laboratories. All rights reserved.
<span class="lineNum">      19 </span>            :  * Copyright (c) 2012-2013 Inria.  All rights reserved.
<span class="lineNum">      20 </span>            :  * Copyright (c) 2014      Intel, Inc. All rights reserved.
<span class="lineNum">      21 </span>            :  * Copyright (c) 2014-2015 Research Organization for Information Science
<span class="lineNum">      22 </span>            :  *                         and Technology (RIST). All rights reserved.
<span class="lineNum">      23 </span>            :  *
<span class="lineNum">      24 </span>            :  * $COPYRIGHT$
<span class="lineNum">      25 </span>            :  *
<span class="lineNum">      26 </span>            :  * Additional copyrights may follow
<span class="lineNum">      27 </span>            :  *
<span class="lineNum">      28 </span>            :  * $HEADER$
<span class="lineNum">      29 </span>            :  */
<span class="lineNum">      30 </span>            : 
<span class="lineNum">      31 </span>            : #include &quot;ompi_config.h&quot;
<span class="lineNum">      32 </span>            : 
<span class="lineNum">      33 </span>            : #ifdef HAVE_SYS_TIME_H
<span class="lineNum">      34 </span>            : #include &lt;sys/time.h&gt;
<span class="lineNum">      35 </span>            : #endif  /* HAVE_SYS_TIME_H */
<span class="lineNum">      36 </span>            : #ifdef HAVE_PTHREAD_H
<span class="lineNum">      37 </span>            : #include &lt;pthread.h&gt;
<span class="lineNum">      38 </span>            : #endif
<span class="lineNum">      39 </span>            : #ifdef HAVE_UNISTD_H
<span class="lineNum">      40 </span>            : #include &lt;unistd.h&gt;
<span class="lineNum">      41 </span>            : #endif
<span class="lineNum">      42 </span>            : 
<span class="lineNum">      43 </span>            : #include &quot;mpi.h&quot;
<span class="lineNum">      44 </span>            : #include &quot;opal/class/opal_list.h&quot;
<span class="lineNum">      45 </span>            : #include &quot;opal/mca/base/base.h&quot;
<span class="lineNum">      46 </span>            : #include &quot;opal/mca/hwloc/base/base.h&quot;
<span class="lineNum">      47 </span>            : #include &quot;opal/runtime/opal_progress.h&quot;
<span class="lineNum">      48 </span>            : #include &quot;opal/threads/threads.h&quot;
<span class="lineNum">      49 </span>            : #include &quot;opal/util/arch.h&quot;
<span class="lineNum">      50 </span>            : #include &quot;opal/util/argv.h&quot;
<span class="lineNum">      51 </span>            : #include &quot;opal/util/output.h&quot;
<span class="lineNum">      52 </span>            : #include &quot;opal/util/error.h&quot;
<span class="lineNum">      53 </span>            : #include &quot;opal/util/stacktrace.h&quot;
<span class="lineNum">      54 </span>            : #include &quot;opal/util/show_help.h&quot;
<span class="lineNum">      55 </span>            : #include &quot;opal/runtime/opal.h&quot;
<span class="lineNum">      56 </span>            : #include &quot;opal/mca/event/event.h&quot;
<span class="lineNum">      57 </span>            : #include &quot;opal/mca/allocator/base/base.h&quot;
<span class="lineNum">      58 </span>            : #include &quot;opal/mca/rcache/base/base.h&quot;
<span class="lineNum">      59 </span>            : #include &quot;opal/mca/rcache/rcache.h&quot;
<span class="lineNum">      60 </span>            : #include &quot;opal/mca/mpool/base/base.h&quot;
<span class="lineNum">      61 </span>            : #include &quot;opal/mca/pmix/pmix.h&quot;
<span class="lineNum">      62 </span>            : #include &quot;opal/util/timings.h&quot;
<span class="lineNum">      63 </span>            : 
<span class="lineNum">      64 </span>            : #include &quot;ompi/constants.h&quot;
<span class="lineNum">      65 </span>            : #include &quot;ompi/mpi/fortran/base/constants.h&quot;
<span class="lineNum">      66 </span>            : #include &quot;ompi/runtime/mpiruntime.h&quot;
<span class="lineNum">      67 </span>            : #include &quot;ompi/runtime/params.h&quot;
<span class="lineNum">      68 </span>            : #include &quot;ompi/communicator/communicator.h&quot;
<span class="lineNum">      69 </span>            : #include &quot;ompi/info/info.h&quot;
<span class="lineNum">      70 </span>            : #include &quot;ompi/errhandler/errcode.h&quot;
<span class="lineNum">      71 </span>            : #include &quot;ompi/errhandler/errhandler.h&quot;
<span class="lineNum">      72 </span>            : #include &quot;ompi/request/request.h&quot;
<span class="lineNum">      73 </span>            : #include &quot;ompi/message/message.h&quot;
<span class="lineNum">      74 </span>            : #include &quot;ompi/op/op.h&quot;
<span class="lineNum">      75 </span>            : #include &quot;ompi/mca/op/op.h&quot;
<span class="lineNum">      76 </span>            : #include &quot;ompi/mca/op/base/base.h&quot;
<span class="lineNum">      77 </span>            : #include &quot;ompi/file/file.h&quot;
<span class="lineNum">      78 </span>            : #include &quot;ompi/attribute/attribute.h&quot;
<span class="lineNum">      79 </span>            : #include &quot;ompi/mca/pml/pml.h&quot;
<span class="lineNum">      80 </span>            : #include &quot;ompi/mca/bml/bml.h&quot;
<span class="lineNum">      81 </span>            : #include &quot;ompi/mca/pml/base/base.h&quot;
<span class="lineNum">      82 </span>            : #include &quot;ompi/mca/bml/base/base.h&quot;
<span class="lineNum">      83 </span>            : #include &quot;ompi/mca/osc/base/base.h&quot;
<span class="lineNum">      84 </span>            : #include &quot;ompi/mca/coll/base/base.h&quot;
<span class="lineNum">      85 </span>            : #include &quot;ompi/mca/io/io.h&quot;
<span class="lineNum">      86 </span>            : #include &quot;ompi/mca/io/base/base.h&quot;
<span class="lineNum">      87 </span>            : #include &quot;ompi/mca/rte/rte.h&quot;
<span class="lineNum">      88 </span>            : #include &quot;ompi/mca/rte/base/base.h&quot;
<span class="lineNum">      89 </span>            : #include &quot;ompi/debuggers/debuggers.h&quot;
<span class="lineNum">      90 </span>            : #include &quot;ompi/proc/proc.h&quot;
<span class="lineNum">      91 </span>            : #include &quot;ompi/mca/pml/base/pml_base_bsend.h&quot;
<span class="lineNum">      92 </span>            : #include &quot;ompi/mca/dpm/base/base.h&quot;
<span class="lineNum">      93 </span>            : #include &quot;ompi/mca/pubsub/base/base.h&quot;
<span class="lineNum">      94 </span>            : #include &quot;ompi/mpiext/mpiext.h&quot;
<span class="lineNum">      95 </span>            : 
<span class="lineNum">      96 </span>            : #if OPAL_ENABLE_FT_CR == 1
<span class="lineNum">      97 </span>            : #include &quot;ompi/mca/crcp/crcp.h&quot;
<span class="lineNum">      98 </span>            : #include &quot;ompi/mca/crcp/base/base.h&quot;
<span class="lineNum">      99 </span>            : #endif
<span class="lineNum">     100 </span>            : #include &quot;ompi/runtime/ompi_cr.h&quot;
<span class="lineNum">     101 </span>            : 
<span class="lineNum">     102 </span>            : #if defined(MEMORY_LINUX_PTMALLOC2) &amp;&amp; MEMORY_LINUX_PTMALLOC2
<span class="lineNum">     103 </span>            : #include &quot;opal/mca/memory/linux/memory_linux.h&quot;
<span class="lineNum">     104 </span>            : /* So this sucks, but with OPAL in its own library that is brought in
<span class="lineNum">     105 </span>            :    implicity from libmpi, there are times when the malloc initialize
<span class="lineNum">     106 </span>            :    hook in the memory component doesn't work.  So we have to do it
<span class="lineNum">     107 </span>            :    from here, since any MPI code is going to call MPI_Init... */
<span class="lineNum">     108 </span>            : OPAL_DECLSPEC void (*__malloc_initialize_hook) (void) =
<span class="lineNum">     109 </span>            :     opal_memory_linux_malloc_init_hook;
<span class="lineNum">     110 </span>            : #endif
<span class="lineNum">     111 </span>            : 
<span class="lineNum">     112 </span>            : /* This is required for the boundaries of the hash tables used to store
<span class="lineNum">     113 </span>            :  * the F90 types returned by the MPI_Type_create_f90_XXX functions.
<span class="lineNum">     114 </span>            :  */
<span class="lineNum">     115 </span>            : #include &lt;float.h&gt;
<span class="lineNum">     116 </span>            : 
<span class="lineNum">     117 </span>            : #if OPAL_CC_USE_PRAGMA_IDENT
<span class="lineNum">     118 </span>            : #pragma ident OMPI_IDENT_STRING
<span class="lineNum">     119 </span>            : #elif OPAL_CC_USE_IDENT
<span class="lineNum">     120 </span>            : #ident OMPI_IDENT_STRING
<span class="lineNum">     121 </span>            : #endif
<span class="lineNum">     122 </span>            : const char ompi_version_string[] = OMPI_IDENT_STRING;
<span class="lineNum">     123 </span>            : 
<span class="lineNum">     124 </span>            : /*
<span class="lineNum">     125 </span>            :  * Global variables and symbols for the MPI layer
<span class="lineNum">     126 </span>            :  */
<span class="lineNum">     127 </span>            : 
<span class="lineNum">     128 </span>            : bool ompi_mpi_init_started = false;
<span class="lineNum">     129 </span>            : bool ompi_mpi_initialized = false;
<span class="lineNum">     130 </span>            : bool ompi_mpi_finalized = false;
<span class="lineNum">     131 </span>            : bool ompi_rte_initialized = false;
<span class="lineNum">     132 </span>            : 
<span class="lineNum">     133 </span>            : bool ompi_mpi_thread_multiple = false;
<span class="lineNum">     134 </span>            : int ompi_mpi_thread_requested = MPI_THREAD_SINGLE;
<span class="lineNum">     135 </span>            : int ompi_mpi_thread_provided = MPI_THREAD_SINGLE;
<span class="lineNum">     136 </span>            : 
<span class="lineNum">     137 </span>            : opal_thread_t *ompi_mpi_main_thread = NULL;
<span class="lineNum">     138 </span>            : 
<span class="lineNum">     139 </span>            : /*
<span class="lineNum">     140 </span>            :  * These variables are for the MPI F08 bindings (F08 must bind Fortran
<span class="lineNum">     141 </span>            :  * varaiables to symbols; it cannot bind Fortran variables to the
<span class="lineNum">     142 </span>            :  * address of a C variable).
<span class="lineNum">     143 </span>            :  */
<span class="lineNum">     144 </span>            : 
<span class="lineNum">     145 </span>            : ompi_predefined_datatype_t *ompi_mpi_character_addr = &amp;ompi_mpi_character;
<span class="lineNum">     146 </span>            : ompi_predefined_datatype_t *ompi_mpi_logical_addr   = &amp;ompi_mpi_logical;
<span class="lineNum">     147 </span>            : ompi_predefined_datatype_t *ompi_mpi_logical1_addr  = &amp;ompi_mpi_logical1;
<span class="lineNum">     148 </span>            : ompi_predefined_datatype_t *ompi_mpi_logical2_addr  = &amp;ompi_mpi_logical2;
<span class="lineNum">     149 </span>            : ompi_predefined_datatype_t *ompi_mpi_logical4_addr  = &amp;ompi_mpi_logical4;
<span class="lineNum">     150 </span>            : ompi_predefined_datatype_t *ompi_mpi_logical8_addr  = &amp;ompi_mpi_logical8;
<span class="lineNum">     151 </span>            : ompi_predefined_datatype_t *ompi_mpi_integer_addr   = &amp;ompi_mpi_integer;
<span class="lineNum">     152 </span>            : ompi_predefined_datatype_t *ompi_mpi_integer1_addr  = &amp;ompi_mpi_integer1;
<span class="lineNum">     153 </span>            : ompi_predefined_datatype_t *ompi_mpi_integer2_addr  = &amp;ompi_mpi_integer2;
<span class="lineNum">     154 </span>            : ompi_predefined_datatype_t *ompi_mpi_integer4_addr  = &amp;ompi_mpi_integer4;
<span class="lineNum">     155 </span>            : ompi_predefined_datatype_t *ompi_mpi_integer8_addr  = &amp;ompi_mpi_integer8;
<span class="lineNum">     156 </span>            : ompi_predefined_datatype_t *ompi_mpi_integer16_addr = &amp;ompi_mpi_integer16;
<span class="lineNum">     157 </span>            : ompi_predefined_datatype_t *ompi_mpi_real_addr      = &amp;ompi_mpi_real;
<span class="lineNum">     158 </span>            : ompi_predefined_datatype_t *ompi_mpi_real4_addr     = &amp;ompi_mpi_real4;
<span class="lineNum">     159 </span>            : ompi_predefined_datatype_t *ompi_mpi_real8_addr     = &amp;ompi_mpi_real8;
<span class="lineNum">     160 </span>            : ompi_predefined_datatype_t *ompi_mpi_real16_addr    = &amp;ompi_mpi_real16;
<span class="lineNum">     161 </span>            : ompi_predefined_datatype_t *ompi_mpi_dblprec_addr   = &amp;ompi_mpi_dblprec;
<span class="lineNum">     162 </span>            : ompi_predefined_datatype_t *ompi_mpi_cplex_addr     = &amp;ompi_mpi_cplex;
<span class="lineNum">     163 </span>            : ompi_predefined_datatype_t *ompi_mpi_complex8_addr  = &amp;ompi_mpi_complex8;
<span class="lineNum">     164 </span>            : ompi_predefined_datatype_t *ompi_mpi_complex16_addr = &amp;ompi_mpi_complex16;
<span class="lineNum">     165 </span>            : ompi_predefined_datatype_t *ompi_mpi_complex32_addr = &amp;ompi_mpi_complex32;
<span class="lineNum">     166 </span>            : ompi_predefined_datatype_t *ompi_mpi_dblcplex_addr  = &amp;ompi_mpi_dblcplex;
<span class="lineNum">     167 </span>            : ompi_predefined_datatype_t *ompi_mpi_2real_addr     = &amp;ompi_mpi_2real;
<span class="lineNum">     168 </span>            : ompi_predefined_datatype_t *ompi_mpi_2dblprec_addr  = &amp;ompi_mpi_2dblprec;
<span class="lineNum">     169 </span>            : ompi_predefined_datatype_t *ompi_mpi_2integer_addr  = &amp;ompi_mpi_2integer;
<span class="lineNum">     170 </span>            : 
<span class="lineNum">     171 </span>            : struct ompi_status_public_t *ompi_mpi_status_ignore_addr =
<span class="lineNum">     172 </span>            :     (ompi_status_public_t *) 0;
<span class="lineNum">     173 </span>            : struct ompi_status_public_t *ompi_mpi_statuses_ignore_addr =
<span class="lineNum">     174 </span>            :     (ompi_status_public_t *) 0;
<span class="lineNum">     175 </span>            : 
<span class="lineNum">     176 </span>            : /*
<span class="lineNum">     177 </span>            :  * These variables are here, rather than under ompi/mpi/c/foo.c
<span class="lineNum">     178 </span>            :  * because it is not sufficient to have a .c file that only contains
<span class="lineNum">     179 </span>            :  * variables -- you must have a function that is invoked from
<span class="lineNum">     180 </span>            :  * elsewhere in the code to guarantee that all linkers will pull in
<span class="lineNum">     181 </span>            :  * the .o file from the library.  Hence, although these are MPI
<span class="lineNum">     182 </span>            :  * constants, we might as well just define them here (i.e., in a file
<span class="lineNum">     183 </span>            :  * that already has a function that is guaranteed to be linked in,
<span class="lineNum">     184 </span>            :  * rather than make a new .c file with the constants and a
<span class="lineNum">     185 </span>            :  * corresponding dummy function that is invoked from this function).
<span class="lineNum">     186 </span>            :  *
<span class="lineNum">     187 </span>            :  * Additionally, there can be/are strange linking paths such that
<span class="lineNum">     188 </span>            :  * ompi_info needs symbols such as ompi_fortran_status_ignore,
<span class="lineNum">     189 </span>            :  * which, if they weren't here with a collection of other global
<span class="lineNum">     190 </span>            :  * symbols that are initialized (which seems to force this .o file to
<span class="lineNum">     191 </span>            :  * be pulled into the resolution process, because ompi_info certainly
<span class="lineNum">     192 </span>            :  * does not call ompi_mpi_init()), would not be able to be found by
<span class="lineNum">     193 </span>            :  * the OSX linker.
<span class="lineNum">     194 </span>            :  *
<span class="lineNum">     195 </span>            :  * NOTE: See the big comment in ompi/mpi/fortran/base/constants.h
<span class="lineNum">     196 </span>            :  * about why we have four symbols for each of the common blocks (e.g.,
<span class="lineNum">     197 </span>            :  * the Fortran equivalent(s) of MPI_STATUS_IGNORE).  Here, we can only
<span class="lineNum">     198 </span>            :  * have *one* value (not four).  So the only thing we can do is make
<span class="lineNum">     199 </span>            :  * it equal to the fortran compiler convention that was selected at
<span class="lineNum">     200 </span>            :  * configure time.  Note that this is also true for the value of
<span class="lineNum">     201 </span>            :  * .TRUE. from the Fortran compiler, so even though Open MPI supports
<span class="lineNum">     202 </span>            :  * all four Fortran symbol conventions, it can only support one
<span class="lineNum">     203 </span>            :  * convention for the two C constants (MPI_FORTRAN_STATUS[ES]_IGNORE)
<span class="lineNum">     204 </span>            :  * and only support one compiler for the value of .TRUE.  Ugh!!
<span class="lineNum">     205 </span>            :  *
<span class="lineNum">     206 </span>            :  * Note that the casts here are ok -- we're *only* comparing pointer
<span class="lineNum">     207 </span>            :  * values (i.e., they'll never be de-referenced).  The global symbols
<span class="lineNum">     208 </span>            :  * are actually of type (ompi_fortran_common_t) (for alignment
<span class="lineNum">     209 </span>            :  * issues), but MPI says that MPI_F_STATUS[ES]_IGNORE must be of type
<span class="lineNum">     210 </span>            :  * (MPI_Fint*).  Hence, we have to cast to make compilers not
<span class="lineNum">     211 </span>            :  * complain.
<span class="lineNum">     212 </span>            :  */
<span class="lineNum">     213 </span>            : #if OMPI_BUILD_FORTRAN_BINDINGS
<span class="lineNum">     214 </span>            : #  if OMPI_FORTRAN_CAPS
<span class="lineNum">     215 </span>            : MPI_Fint *MPI_F_STATUS_IGNORE = (MPI_Fint*) &amp;MPI_FORTRAN_STATUS_IGNORE;
<span class="lineNum">     216 </span>            : MPI_Fint *MPI_F_STATUSES_IGNORE = (MPI_Fint*) &amp;MPI_FORTRAN_STATUSES_IGNORE;
<span class="lineNum">     217 </span>            : #  elif OMPI_FORTRAN_PLAIN
<span class="lineNum">     218 </span>            : MPI_Fint *MPI_F_STATUS_IGNORE = (MPI_Fint*) &amp;mpi_fortran_status_ignore;
<span class="lineNum">     219 </span>            : MPI_Fint *MPI_F_STATUSES_IGNORE = (MPI_Fint*) &amp;mpi_fortran_statuses_ignore;
<span class="lineNum">     220 </span>            : #  elif OMPI_FORTRAN_SINGLE_UNDERSCORE
<span class="lineNum">     221 </span>            : MPI_Fint *MPI_F_STATUS_IGNORE = (MPI_Fint*) &amp;mpi_fortran_status_ignore_;
<span class="lineNum">     222 </span>            : MPI_Fint *MPI_F_STATUSES_IGNORE = (MPI_Fint*) &amp;mpi_fortran_statuses_ignore_;
<span class="lineNum">     223 </span>            : #  elif OMPI_FORTRAN_DOUBLE_UNDERSCORE
<span class="lineNum">     224 </span>            : MPI_Fint *MPI_F_STATUS_IGNORE = (MPI_Fint*) &amp;mpi_fortran_status_ignore__;
<span class="lineNum">     225 </span>            : MPI_Fint *MPI_F_STATUSES_IGNORE = (MPI_Fint*) &amp;mpi_fortran_statuses_ignore__;
<span class="lineNum">     226 </span>            : #  else
<span class="lineNum">     227 </span>            : #    error Unrecognized Fortran name mangling scheme
<span class="lineNum">     228 </span>            : #  endif
<span class="lineNum">     229 </span>            : #else
<span class="lineNum">     230 </span>            : MPI_Fint *MPI_F_STATUS_IGNORE = NULL;
<span class="lineNum">     231 </span>            : MPI_Fint *MPI_F_STATUSES_IGNORE = NULL;
<span class="lineNum">     232 </span>            : #endif  /* OMPI_BUILD_FORTRAN_BINDINGS */
<span class="lineNum">     233 </span>            : 
<span class="lineNum">     234 </span>            : 
<span class="lineNum">     235 </span>            : /* Constants for the Fortran layer.  These values are referred to via
<span class="lineNum">     236 </span>            :    common blocks in the Fortran equivalents.  See
<span class="lineNum">     237 </span>            :    ompi/mpi/fortran/base/constants.h for a more detailed explanation.
<span class="lineNum">     238 </span>            : 
<span class="lineNum">     239 </span>            :    The values are *NOT* initialized.  We do not use the values of
<span class="lineNum">     240 </span>            :    these constants; only their addresses (because they're always
<span class="lineNum">     241 </span>            :    passed by reference by Fortran).
<span class="lineNum">     242 </span>            : 
<span class="lineNum">     243 </span>            :    Initializing upon instantiation these can reveal size and/or
<span class="lineNum">     244 </span>            :    alignment differences between Fortran and C (!) which can cause
<span class="lineNum">     245 </span>            :    warnings or errors upon linking (e.g., making static libraries with
<span class="lineNum">     246 </span>            :    the intel 9.0 compilers on 64 bit platforms shows alignment
<span class="lineNum">     247 </span>            :    differences between libmpi.a and the user's application, resulting
<span class="lineNum">     248 </span>            :    in a linker warning).  FWIW, if you initialize these variables in
<span class="lineNum">     249 </span>            :    functions (i.e., not at the instantiation in the global scope), the
<span class="lineNum">     250 </span>            :    linker somehow &quot;figures it all out&quot; (w.r.t. different alignments
<span class="lineNum">     251 </span>            :    between fortan common blocks and the corresponding C variables) and
<span class="lineNum">     252 </span>            :    no linker warnings occur.
<span class="lineNum">     253 </span>            : 
<span class="lineNum">     254 </span>            :    Note that the rationale for the types of each of these variables is
<span class="lineNum">     255 </span>            :    discussed in ompi/include/mpif-common.h.  Do not change the types
<span class="lineNum">     256 </span>            :    without also modifying ompi/mpi/fortran/base/constants.h and
<span class="lineNum">     257 </span>            :    ompi/include/mpif-common.h.
<span class="lineNum">     258 </span>            :  */
<span class="lineNum">     259 </span>            : 
<span class="lineNum">     260 </span>            : #include &quot;mpif-c-constants.h&quot;
<span class="lineNum">     261 </span>            : 
<span class="lineNum">     262 </span>            : /*
<span class="lineNum">     263 </span>            :  * Hash tables for MPI_Type_create_f90* functions
<span class="lineNum">     264 </span>            :  */
<span class="lineNum">     265 </span>            : opal_hash_table_t ompi_mpi_f90_integer_hashtable = {{0}};
<span class="lineNum">     266 </span>            : opal_hash_table_t ompi_mpi_f90_real_hashtable = {{0}};
<span class="lineNum">     267 </span>            : opal_hash_table_t ompi_mpi_f90_complex_hashtable = {{0}};
<span class="lineNum">     268 </span>            : 
<span class="lineNum">     269 </span>            : /*
<span class="lineNum">     270 </span>            :  * Per MPI-2:9.5.3, MPI_REGISTER_DATAREP is a memory leak.  There is
<span class="lineNum">     271 </span>            :  * no way to *de*register datareps once they've been registered.  So
<span class="lineNum">     272 </span>            :  * we have to track all registrations here so that they can be
<span class="lineNum">     273 </span>            :  * de-registered during MPI_FINALIZE so that memory-tracking debuggers
<span class="lineNum">     274 </span>            :  * don't show Open MPI as leaking memory.
<span class="lineNum">     275 </span>            :  */
<span class="lineNum">     276 </span>            : opal_list_t ompi_registered_datareps = {{0}};
<span class="lineNum">     277 </span>            : 
<span class="lineNum">     278 </span>            : bool ompi_enable_timing = false, ompi_enable_timing_ext = false;
<span class="lineNum">     279 </span>            : extern bool ompi_mpi_yield_when_idle;
<span class="lineNum">     280 </span>            : extern int ompi_mpi_event_tick_rate;
<span class="lineNum">     281 </span>            : 
<span class="lineNum">     282 </span>            : /**
<span class="lineNum">     283 </span>            :  * Static functions used to configure the interactions between the OPAL and
<span class="lineNum">     284 </span>            :  * the runtime.
<a name="285"><span class="lineNum">     285 </span>            :  */</a>
<span class="lineNum">     286 </span>            : static char*
<span class="lineNum">     287 </span><span class="lineNoCov">          0 : _process_name_print_for_opal(const opal_process_name_t procname)</span>
<span class="lineNum">     288 </span>            : {
<span class="lineNum">     289 </span><span class="lineNoCov">          0 :     ompi_process_name_t* rte_name = (ompi_process_name_t*)&amp;procname;</span>
<span class="lineNum">     290 </span><span class="lineNoCov">          0 :     return OMPI_NAME_PRINT(rte_name);</span>
<span class="lineNum">     291 </span>            : }
<a name="292"><span class="lineNum">     292 </span>            : </a>
<span class="lineNum">     293 </span>            : static int
<span class="lineNum">     294 </span><span class="lineNoCov">          0 : _process_name_compare(const opal_process_name_t p1, const opal_process_name_t p2)</span>
<span class="lineNum">     295 </span>            : {
<span class="lineNum">     296 </span><span class="lineNoCov">          0 :     ompi_process_name_t* o1 = (ompi_process_name_t*)&amp;p1;</span>
<span class="lineNum">     297 </span><span class="lineNoCov">          0 :     ompi_process_name_t* o2 = (ompi_process_name_t*)&amp;p2;</span>
<span class="lineNum">     298 </span><span class="lineNoCov">          0 :     return ompi_rte_compare_name_fields(OMPI_RTE_CMP_ALL, o1, o2);</span>
<a name="299"><span class="lineNum">     299 </span>            : }</a>
<span class="lineNum">     300 </span>            : 
<span class="lineNum">     301 </span><span class="lineCov">          2 : void ompi_mpi_thread_level(int requested, int *provided)</span>
<span class="lineNum">     302 </span>            : {
<span class="lineNum">     303 </span>            :     /**
<span class="lineNum">     304 </span>            :      * These values are monotonic; MPI_THREAD_SINGLE &lt; MPI_THREAD_FUNNELED
<span class="lineNum">     305 </span>            :      *                             &lt; MPI_THREAD_SERIALIZED &lt; MPI_THREAD_MULTIPLE.
<span class="lineNum">     306 </span>            :      * If possible, the call will return provided = required. Failing this,
<span class="lineNum">     307 </span>            :      * the call will return the least supported level such that
<span class="lineNum">     308 </span>            :      * provided &gt; required. Finally, if the user requirement cannot be
<span class="lineNum">     309 </span>            :      * satisfied, then the call will return in provided the highest
<span class="lineNum">     310 </span>            :      * supported level.
<span class="lineNum">     311 </span>            :      */
<span class="lineNum">     312 </span><span class="lineCov">          2 :     ompi_mpi_thread_requested = requested;</span>
<span class="lineNum">     313 </span>            : 
<span class="lineNum">     314 </span>            :     if (OMPI_ENABLE_THREAD_MULTIPLE == 1) {
<span class="lineNum">     315 </span>            :         ompi_mpi_thread_provided = *provided = requested;
<span class="lineNum">     316 </span>            :     } else {
<span class="lineNum">     317 </span><span class="lineCov">          2 :         if (MPI_THREAD_MULTIPLE == requested) {</span>
<span class="lineNum">     318 </span><span class="lineNoCov">          0 :             ompi_mpi_thread_provided = *provided = MPI_THREAD_SERIALIZED;</span>
<span class="lineNum">     319 </span>            :         } else {
<span class="lineNum">     320 </span><span class="lineCov">          2 :             ompi_mpi_thread_provided = *provided = requested;</span>
<span class="lineNum">     321 </span>            :         }
<span class="lineNum">     322 </span>            :     }
<span class="lineNum">     323 </span>            : 
<span class="lineNum">     324 </span><span class="lineCov">          2 :     if (!ompi_mpi_main_thread) {</span>
<span class="lineNum">     325 </span><span class="lineCov">          2 :         ompi_mpi_main_thread = opal_thread_get_self();</span>
<span class="lineNum">     326 </span>            :     }
<span class="lineNum">     327 </span>            : 
<span class="lineNum">     328 </span><span class="lineCov">          2 :     ompi_mpi_thread_multiple = (ompi_mpi_thread_provided ==</span>
<span class="lineNum">     329 </span>            :                                 MPI_THREAD_MULTIPLE);
<a name="330"><span class="lineNum">     330 </span><span class="lineCov">          2 : }</span></a>
<span class="lineNum">     331 </span>            : 
<span class="lineNum">     332 </span><span class="lineCov">          2 : static int ompi_register_mca_variables(void)</span>
<span class="lineNum">     333 </span>            : {
<span class="lineNum">     334 </span>            :     int ret;
<span class="lineNum">     335 </span>            : 
<span class="lineNum">     336 </span>            :     /* Register MPI variables */
<span class="lineNum">     337 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_mpi_register_params())) {</span>
<span class="lineNum">     338 </span><span class="lineNoCov">          0 :         return ret;</span>
<span class="lineNum">     339 </span>            :     }
<span class="lineNum">     340 </span>            : 
<span class="lineNum">     341 </span>            :     /* check to see if we want timing information */
<span class="lineNum">     342 </span><span class="lineCov">          2 :     ompi_enable_timing = false;</span>
<span class="lineNum">     343 </span><span class="lineCov">          2 :     (void) mca_base_var_register(&quot;ompi&quot;, &quot;ompi&quot;, NULL, &quot;timing&quot;,</span>
<span class="lineNum">     344 </span>            :                                  &quot;Request that critical timing loops be measured&quot;,
<span class="lineNum">     345 </span>            :                                  MCA_BASE_VAR_TYPE_BOOL, NULL, 0, 0,
<span class="lineNum">     346 </span>            :                                  OPAL_INFO_LVL_9,
<span class="lineNum">     347 </span>            :                                  MCA_BASE_VAR_SCOPE_READONLY,
<span class="lineNum">     348 </span>            :                                  &amp;ompi_enable_timing);
<span class="lineNum">     349 </span>            : 
<span class="lineNum">     350 </span><span class="lineCov">          2 :     ompi_enable_timing_ext = false;</span>
<span class="lineNum">     351 </span><span class="lineCov">          2 :     (void) mca_base_var_register(&quot;ompi&quot;, &quot;ompi&quot;, NULL, &quot;timing_ext&quot;,</span>
<span class="lineNum">     352 </span>            :                                  &quot;Request that critical timing loops be measured&quot;,
<span class="lineNum">     353 </span>            :                                  MCA_BASE_VAR_TYPE_BOOL, NULL, 0, 0,
<span class="lineNum">     354 </span>            :                                  OPAL_INFO_LVL_9,
<span class="lineNum">     355 </span>            :                                  MCA_BASE_VAR_SCOPE_READONLY,
<span class="lineNum">     356 </span>            :                                  &amp;ompi_enable_timing_ext);
<span class="lineNum">     357 </span><span class="lineCov">          2 :     return OMPI_SUCCESS;</span>
<a name="358"><span class="lineNum">     358 </span>            : }</a>
<span class="lineNum">     359 </span>            : 
<span class="lineNum">     360 </span><span class="lineCov">          2 : int ompi_mpi_init(int argc, char **argv, int requested, int *provided)</span>
<span class="lineNum">     361 </span>            : {
<span class="lineNum">     362 </span>            :     int ret;
<span class="lineNum">     363 </span>            :     ompi_proc_t** procs;
<span class="lineNum">     364 </span>            :     size_t nprocs;
<span class="lineNum">     365 </span><span class="lineCov">          2 :     char *error = NULL;</span>
<span class="lineNum">     366 </span><span class="lineCov">          2 :     char *cmd=NULL, *av=NULL;</span>
<span class="lineNum">     367 </span>            :     OPAL_TIMING_DECLARE(tm);
<span class="lineNum">     368 </span>            :     OPAL_TIMING_INIT_EXT(&amp;tm, OPAL_TIMING_GET_TIME_OF_DAY);
<span class="lineNum">     369 </span>            : 
<span class="lineNum">     370 </span>            :     /* bitflag of the thread level support provided. To be used
<span class="lineNum">     371 </span>            :      * for the modex in order to work in heterogeneous environments. */
<span class="lineNum">     372 </span>            :     uint8_t threadlevel_bf;
<span class="lineNum">     373 </span>            : 
<span class="lineNum">     374 </span>            :     /* Indicate that we have *started* MPI_INIT*.  MPI_FINALIZE has
<span class="lineNum">     375 </span>            :        something sorta similar in a static local variable in
<span class="lineNum">     376 </span>            :        ompi_mpi_finalize(). */
<span class="lineNum">     377 </span><span class="lineCov">          2 :     ompi_mpi_init_started = true;</span>
<span class="lineNum">     378 </span>            : 
<span class="lineNum">     379 </span>            :     /* Setup enough to check get/set MCA params */
<span class="lineNum">     380 </span>            : 
<span class="lineNum">     381 </span><span class="lineCov">          2 :     if (OPAL_SUCCESS != (ret = opal_init_util(&amp;argc, &amp;argv))) {</span>
<span class="lineNum">     382 </span><span class="lineNoCov">          0 :         error = &quot;ompi_mpi_init: opal_init_util failed&quot;;</span>
<span class="lineNum">     383 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     384 </span>            :     }
<span class="lineNum">     385 </span>            : 
<span class="lineNum">     386 </span>            :     /* Convince OPAL to use our naming scheme */
<span class="lineNum">     387 </span><span class="lineCov">          2 :     opal_process_name_print = _process_name_print_for_opal;</span>
<span class="lineNum">     388 </span><span class="lineCov">          2 :     opal_compare_proc = _process_name_compare;</span>
<span class="lineNum">     389 </span>            : 
<span class="lineNum">     390 </span>            :     /* Register MCA variables */
<span class="lineNum">     391 </span><span class="lineCov">          2 :     if (OPAL_SUCCESS != (ret = ompi_register_mca_variables())) {</span>
<span class="lineNum">     392 </span><span class="lineNoCov">          0 :         error = &quot;ompi_mpi_init: ompi_register_mca_variables failed&quot;;</span>
<span class="lineNum">     393 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     394 </span>            :     }
<span class="lineNum">     395 </span>            : 
<span class="lineNum">     396 </span><span class="lineCov">          2 :     if (OPAL_SUCCESS != (ret = opal_arch_set_fortran_logical_size(sizeof(ompi_fortran_logical_t)))) {</span>
<span class="lineNum">     397 </span><span class="lineNoCov">          0 :         error = &quot;ompi_mpi_init: opal_arch_set_fortran_logical_size failed&quot;;</span>
<span class="lineNum">     398 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     399 </span>            :     }
<span class="lineNum">     400 </span>            : 
<span class="lineNum">     401 </span>            :     /* _After_ opal_init_util() but _before_ orte_init(), we need to
<span class="lineNum">     402 </span>            :        set an MCA param that tells libevent that it's ok to use any
<span class="lineNum">     403 </span>            :        mechanism in libevent that is available on this platform (e.g.,
<span class="lineNum">     404 </span>            :        epoll and friends).  Per opal/event/event.s, we default to
<span class="lineNum">     405 </span>            :        select/poll -- but we know that MPI processes won't be using
<span class="lineNum">     406 </span>            :        pty's with the event engine, so it's ok to relax this
<span class="lineNum">     407 </span>            :        constraint and let any fd-monitoring mechanism be used. */
<span class="lineNum">     408 </span>            : 
<span class="lineNum">     409 </span><span class="lineCov">          2 :     ret = mca_base_var_find(&quot;opal&quot;, &quot;event&quot;, &quot;*&quot;, &quot;event_include&quot;);</span>
<span class="lineNum">     410 </span><span class="lineCov">          2 :     if (ret &gt;= 0) {</span>
<span class="lineNum">     411 </span><span class="lineNoCov">          0 :         char *allvalue = &quot;all&quot;;</span>
<span class="lineNum">     412 </span>            :         /* We have to explicitly &quot;set&quot; the MCA param value here
<span class="lineNum">     413 </span>            :            because libevent initialization will re-register the MCA
<span class="lineNum">     414 </span>            :            param and therefore override the default. Setting the value
<span class="lineNum">     415 </span>            :            here puts the desired value (&quot;all&quot;) in different storage
<span class="lineNum">     416 </span>            :            that is not overwritten if/when the MCA param is
<span class="lineNum">     417 </span>            :            re-registered. This is unless the user has specified a different
<span class="lineNum">     418 </span>            :            value for this MCA parameter. Make sure we check to see if the
<span class="lineNum">     419 </span>            :            default is specified before forcing &quot;all&quot; in case that is not what
<span class="lineNum">     420 </span>            :            the user desires. Note that we do *NOT* set this value as an
<span class="lineNum">     421 </span>            :            environment variable, just so that it won't be inherited by
<span class="lineNum">     422 </span>            :            any spawned processes and potentially cause unintented
<span class="lineNum">     423 </span>            :            side-effects with launching RTE tools... */
<span class="lineNum">     424 </span><span class="lineNoCov">          0 :         mca_base_var_set_value(ret, allvalue, 4, MCA_BASE_VAR_SOURCE_DEFAULT, NULL);</span>
<span class="lineNum">     425 </span>            :     }
<span class="lineNum">     426 </span>            : 
<span class="lineNum">     427 </span>            :     OPAL_TIMING_MSTART((&amp;tm,&quot;time from start to completion of rte_init&quot;));
<span class="lineNum">     428 </span>            : 
<span class="lineNum">     429 </span>            :     /* if we were not externally started, then we need to setup
<span class="lineNum">     430 </span>            :      * some envars so the MPI_INFO_ENV can get the cmd name
<span class="lineNum">     431 </span>            :      * and argv (but only if the user supplied a non-NULL argv!), and
<span class="lineNum">     432 </span>            :      * the requested thread level
<span class="lineNum">     433 </span>            :      */
<span class="lineNum">     434 </span><span class="lineCov">          2 :     if (NULL == getenv(&quot;OMPI_COMMAND&quot;) &amp;&amp; NULL != argv &amp;&amp; NULL != argv[0]) {</span>
<span class="lineNum">     435 </span><span class="lineNoCov">          0 :         asprintf(&amp;cmd, &quot;OMPI_COMMAND=%s&quot;, argv[0]);</span>
<span class="lineNum">     436 </span><span class="lineNoCov">          0 :         putenv(cmd);</span>
<span class="lineNum">     437 </span>            :     }
<span class="lineNum">     438 </span><span class="lineCov">          2 :     if (NULL == getenv(&quot;OMPI_ARGV&quot;) &amp;&amp; 1 &lt; argc) {</span>
<span class="lineNum">     439 </span>            :         char *tmp;
<span class="lineNum">     440 </span><span class="lineNoCov">          0 :         tmp = opal_argv_join(&amp;argv[1], ' ');</span>
<span class="lineNum">     441 </span><span class="lineNoCov">          0 :         asprintf(&amp;av, &quot;OMPI_ARGV=%s&quot;, tmp);</span>
<span class="lineNum">     442 </span><span class="lineNoCov">          0 :         free(tmp);</span>
<span class="lineNum">     443 </span><span class="lineNoCov">          0 :         putenv(av);</span>
<span class="lineNum">     444 </span>            :     }
<span class="lineNum">     445 </span>            : 
<span class="lineNum">     446 </span>            :     /* open the rte framework */
<span class="lineNum">     447 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_rte_base_framework, 0))) {</span>
<span class="lineNum">     448 </span><span class="lineNoCov">          0 :         error = &quot;ompi_rte_base_open() failed&quot;;</span>
<span class="lineNum">     449 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     450 </span>            :     }
<span class="lineNum">     451 </span>            :     /* no select is required as this is a static framework */
<span class="lineNum">     452 </span>            : 
<span class="lineNum">     453 </span>            :     /* Setup RTE */
<span class="lineNum">     454 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_rte_init(NULL, NULL))) {</span>
<span class="lineNum">     455 </span><span class="lineNoCov">          0 :         error = &quot;ompi_mpi_init: ompi_rte_init failed&quot;;</span>
<span class="lineNum">     456 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     457 </span>            :     }
<span class="lineNum">     458 </span><span class="lineCov">          2 :     ompi_rte_initialized = true;</span>
<span class="lineNum">     459 </span>            : 
<span class="lineNum">     460 </span>            :     /* check for timing request - get stop time and report elapsed time if so */
<span class="lineNum">     461 </span>            :     OPAL_TIMING_MNEXT((&amp;tm,&quot;time from completion of rte_init to modex&quot;));
<span class="lineNum">     462 </span>            : 
<span class="lineNum">     463 </span>            : #if OPAL_HAVE_HWLOC
<span class="lineNum">     464 </span>            :     /* if hwloc is available but didn't get setup for some
<span class="lineNum">     465 </span>            :      * reason, do so now
<span class="lineNum">     466 </span>            :      */
<span class="lineNum">     467 </span><span class="lineCov">          2 :     if (NULL == opal_hwloc_topology) {</span>
<span class="lineNum">     468 </span><span class="lineNoCov">          0 :         if (OPAL_SUCCESS != (ret = opal_hwloc_base_get_topology())) {</span>
<span class="lineNum">     469 </span><span class="lineNoCov">          0 :             error = &quot;Topology init&quot;;</span>
<span class="lineNum">     470 </span><span class="lineNoCov">          0 :             goto error;</span>
<span class="lineNum">     471 </span>            :         }
<span class="lineNum">     472 </span>            :     }
<span class="lineNum">     473 </span>            : #endif
<span class="lineNum">     474 </span>            : 
<span class="lineNum">     475 </span>            :     /* Register the default errhandler callback - RTE will ignore if it
<span class="lineNum">     476 </span>            :      * doesn't support this capability
<span class="lineNum">     477 </span>            :      */
<span class="lineNum">     478 </span><span class="lineCov">          2 :     ompi_rte_register_errhandler(ompi_errhandler_runtime_callback,</span>
<span class="lineNum">     479 </span>            :                                  OMPI_RTE_ERRHANDLER_LAST);
<span class="lineNum">     480 </span>            : 
<span class="lineNum">     481 </span>            :     /* Figure out the final MPI thread levels.  If we were not
<span class="lineNum">     482 </span>            :        compiled for support for MPI threads, then don't allow
<span class="lineNum">     483 </span>            :        MPI_THREAD_MULTIPLE.  Set this stuff up here early in the
<span class="lineNum">     484 </span>            :        process so that other components can make decisions based on
<span class="lineNum">     485 </span>            :        this value. */
<span class="lineNum">     486 </span>            : 
<span class="lineNum">     487 </span><span class="lineCov">          2 :     ompi_mpi_thread_level(requested, provided);</span>
<span class="lineNum">     488 </span>            : 
<span class="lineNum">     489 </span>            :     /* determine the bitflag belonging to the threadlevel_support provided */
<span class="lineNum">     490 </span><span class="lineCov">          2 :     memset ( &amp;threadlevel_bf, 0, sizeof(uint8_t));</span>
<span class="lineNum">     491 </span><span class="lineCov">          2 :     OMPI_THREADLEVEL_SET_BITFLAG ( ompi_mpi_thread_provided, threadlevel_bf );</span>
<span class="lineNum">     492 </span>            : 
<span class="lineNum">     493 </span>            : #if OMPI_ENABLE_THREAD_MULTIPLE
<span class="lineNum">     494 </span>            :     /* add this bitflag to the modex */
<span class="lineNum">     495 </span>            :     OPAL_MODEX_SEND_STRING(ret, PMIX_SYNC_REQD, PMIX_GLOBAL,
<span class="lineNum">     496 </span>            :                            &quot;MPI_THREAD_LEVEL&quot;, &amp;threadlevel_bf, sizeof(uint8_t));
<span class="lineNum">     497 </span>            :     if (OPAL_SUCCESS != ret) {
<span class="lineNum">     498 </span>            :         error = &quot;ompi_mpi_init: modex send thread level&quot;;
<span class="lineNum">     499 </span>            :         goto error;
<span class="lineNum">     500 </span>            :     }
<span class="lineNum">     501 </span>            : #endif
<span class="lineNum">     502 </span>            : 
<span class="lineNum">     503 </span>            :     /* If thread support was enabled, then setup OPAL to allow for
<span class="lineNum">     504 </span>            :        them. */
<span class="lineNum">     505 </span><span class="lineCov">          2 :     if ((OPAL_ENABLE_PROGRESS_THREADS == 1) ||</span>
<span class="lineNum">     506 </span><span class="lineCov">          2 :         (*provided != MPI_THREAD_SINGLE)) {</span>
<span class="lineNum">     507 </span><span class="lineNoCov">          0 :         opal_set_using_threads(true);</span>
<span class="lineNum">     508 </span>            :     }
<span class="lineNum">     509 </span>            : 
<span class="lineNum">     510 </span>            :     /* initialize datatypes. This step should be done early as it will
<span class="lineNum">     511 </span>            :      * create the local convertor and local arch used in the proc
<span class="lineNum">     512 </span>            :      * init.
<span class="lineNum">     513 </span>            :      */
<span class="lineNum">     514 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_datatype_init())) {</span>
<span class="lineNum">     515 </span><span class="lineNoCov">          0 :         error = &quot;ompi_datatype_init() failed&quot;;</span>
<span class="lineNum">     516 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     517 </span>            :     }
<span class="lineNum">     518 </span>            : 
<span class="lineNum">     519 </span>            :     /* Initialize OMPI procs */
<span class="lineNum">     520 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_proc_init())) {</span>
<span class="lineNum">     521 </span><span class="lineNoCov">          0 :         error = &quot;mca_proc_init() failed&quot;;</span>
<span class="lineNum">     522 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     523 </span>            :     }
<span class="lineNum">     524 </span>            : 
<span class="lineNum">     525 </span>            :     /* Initialize the op framework. This has to be done *after*
<span class="lineNum">     526 </span>            :        ddt_init, but befor mca_coll_base_open, since some collective
<span class="lineNum">     527 </span>            :        modules (e.g., the hierarchical coll component) may need ops in
<span class="lineNum">     528 </span>            :        their query function. */
<span class="lineNum">     529 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_op_base_framework, 0))) {</span>
<span class="lineNum">     530 </span><span class="lineNoCov">          0 :         error = &quot;ompi_op_base_open() failed&quot;;</span>
<span class="lineNum">     531 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     532 </span>            :     }
<span class="lineNum">     533 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS !=</span>
<span class="lineNum">     534 </span><span class="lineCov">          2 :         (ret = ompi_op_base_find_available(OPAL_ENABLE_PROGRESS_THREADS,</span>
<span class="lineNum">     535 </span>            :                                            ompi_mpi_thread_multiple))) {
<span class="lineNum">     536 </span><span class="lineNoCov">          0 :         error = &quot;ompi_op_base_find_available() failed&quot;;</span>
<span class="lineNum">     537 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     538 </span>            :     }
<span class="lineNum">     539 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_op_init())) {</span>
<span class="lineNum">     540 </span><span class="lineNoCov">          0 :         error = &quot;ompi_op_init() failed&quot;;</span>
<span class="lineNum">     541 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     542 </span>            :     }
<span class="lineNum">     543 </span>            : 
<span class="lineNum">     544 </span>            :     /* Open up MPI-related MCA components */
<span class="lineNum">     545 </span>            : 
<span class="lineNum">     546 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;opal_allocator_base_framework, 0))) {</span>
<span class="lineNum">     547 </span><span class="lineNoCov">          0 :         error = &quot;mca_allocator_base_open() failed&quot;;</span>
<span class="lineNum">     548 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     549 </span>            :     }
<span class="lineNum">     550 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;opal_rcache_base_framework, 0))) {</span>
<span class="lineNum">     551 </span><span class="lineNoCov">          0 :         error = &quot;mca_rcache_base_open() failed&quot;;</span>
<span class="lineNum">     552 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     553 </span>            :     }
<span class="lineNum">     554 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;opal_mpool_base_framework, 0))) {</span>
<span class="lineNum">     555 </span><span class="lineNoCov">          0 :         error = &quot;mca_mpool_base_open() failed&quot;;</span>
<span class="lineNum">     556 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     557 </span>            :     }
<span class="lineNum">     558 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_bml_base_framework, 0))) {</span>
<span class="lineNum">     559 </span><span class="lineNoCov">          0 :         error = &quot;mca_bml_base_open() failed&quot;;</span>
<span class="lineNum">     560 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     561 </span>            :     }
<span class="lineNum">     562 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_pml_base_framework, 0))) {</span>
<span class="lineNum">     563 </span><span class="lineNoCov">          0 :         error = &quot;mca_pml_base_open() failed&quot;;</span>
<span class="lineNum">     564 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     565 </span>            :     }
<span class="lineNum">     566 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_coll_base_framework, 0))) {</span>
<span class="lineNum">     567 </span><span class="lineNoCov">          0 :         error = &quot;mca_coll_base_open() failed&quot;;</span>
<span class="lineNum">     568 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     569 </span>            :     }
<span class="lineNum">     570 </span>            : 
<span class="lineNum">     571 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_osc_base_framework, 0))) {</span>
<span class="lineNum">     572 </span><span class="lineNoCov">          0 :         error = &quot;ompi_osc_base_open() failed&quot;;</span>
<span class="lineNum">     573 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     574 </span>            :     }
<span class="lineNum">     575 </span>            : 
<span class="lineNum">     576 </span>            : #if OPAL_ENABLE_FT_CR == 1
<span class="lineNum">     577 </span>            :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_crcp_base_framework, 0))) {
<span class="lineNum">     578 </span>            :         error = &quot;ompi_crcp_base_open() failed&quot;;
<span class="lineNum">     579 </span>            :         goto error;
<span class="lineNum">     580 </span>            :     }
<span class="lineNum">     581 </span>            : #endif
<span class="lineNum">     582 </span>            : 
<span class="lineNum">     583 </span>            :     /* In order to reduce the common case for MPI apps (where they
<span class="lineNum">     584 </span>            :        don't use MPI-2 IO or MPI-1 topology functions), the io and
<span class="lineNum">     585 </span>            :        topo frameworks are initialized lazily, at the first use of
<span class="lineNum">     586 </span>            :        relevant functions (e.g., MPI_FILE_*, MPI_CART_*, MPI_GRAPH_*),
<span class="lineNum">     587 </span>            :        so they are not opened here. */
<span class="lineNum">     588 </span>            : 
<span class="lineNum">     589 </span>            :     /* Select which MPI components to use */
<span class="lineNum">     590 </span>            : 
<span class="lineNum">     591 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS !=</span>
<span class="lineNum">     592 </span><span class="lineCov">          2 :         (ret = mca_mpool_base_init(OPAL_ENABLE_PROGRESS_THREADS,</span>
<span class="lineNum">     593 </span>            :                                    ompi_mpi_thread_multiple))) {
<span class="lineNum">     594 </span><span class="lineNoCov">          0 :         error = &quot;mca_mpool_base_init() failed&quot;;</span>
<span class="lineNum">     595 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     596 </span>            :     }
<span class="lineNum">     597 </span>            : 
<span class="lineNum">     598 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS !=</span>
<span class="lineNum">     599 </span><span class="lineCov">          2 :         (ret = mca_pml_base_select(OPAL_ENABLE_PROGRESS_THREADS,</span>
<span class="lineNum">     600 </span>            :                                    ompi_mpi_thread_multiple))) {
<span class="lineNum">     601 </span><span class="lineNoCov">          0 :         error = &quot;mca_pml_base_select() failed&quot;;</span>
<span class="lineNum">     602 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     603 </span>            :     }
<span class="lineNum">     604 </span>            : 
<span class="lineNum">     605 </span>            :     /* check for timing request - get stop time and report elapsed time if so */
<span class="lineNum">     606 </span>            :     OPAL_TIMING_MNEXT((&amp;tm,&quot;time to execute modex&quot;));
<span class="lineNum">     607 </span>            : 
<span class="lineNum">     608 </span>            :     /* exchange connection info - this function may also act as a barrier
<span class="lineNum">     609 </span>            :      * if data exchange is required. The modex occurs solely across procs
<span class="lineNum">     610 </span>            :      * in our job, so no proc array is passed. If a barrier is required,
<span class="lineNum">     611 </span>            :      * the &quot;fence&quot; function will perform it internally
<span class="lineNum">     612 </span>            :      */
<span class="lineNum">     613 </span><span class="lineCov">          2 :     OPAL_FENCE(NULL, 0, NULL, NULL);</span>
<span class="lineNum">     614 </span>            : 
<span class="lineNum">     615 </span>            :     OPAL_TIMING_MNEXT((&amp;tm,&quot;time from modex to first barrier&quot;));
<span class="lineNum">     616 </span>            : 
<span class="lineNum">     617 </span>            :     /* select buffered send allocator component to be used */
<span class="lineNum">     618 </span><span class="lineCov">          2 :     if( OMPI_SUCCESS !=</span>
<span class="lineNum">     619 </span><span class="lineCov">          2 :         (ret = mca_pml_base_bsend_init(ompi_mpi_thread_multiple))) {</span>
<span class="lineNum">     620 </span><span class="lineNoCov">          0 :         error = &quot;mca_pml_base_bsend_init() failed&quot;;</span>
<span class="lineNum">     621 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     622 </span>            :     }
<span class="lineNum">     623 </span>            : 
<span class="lineNum">     624 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS !=</span>
<span class="lineNum">     625 </span><span class="lineCov">          2 :         (ret = mca_coll_base_find_available(OPAL_ENABLE_PROGRESS_THREADS,</span>
<span class="lineNum">     626 </span>            :                                             ompi_mpi_thread_multiple))) {
<span class="lineNum">     627 </span><span class="lineNoCov">          0 :         error = &quot;mca_coll_base_find_available() failed&quot;;</span>
<span class="lineNum">     628 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     629 </span>            :     }
<span class="lineNum">     630 </span>            : 
<span class="lineNum">     631 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS !=</span>
<span class="lineNum">     632 </span><span class="lineCov">          2 :         (ret = ompi_osc_base_find_available(OPAL_ENABLE_PROGRESS_THREADS,</span>
<span class="lineNum">     633 </span>            :                                             ompi_mpi_thread_multiple))) {
<span class="lineNum">     634 </span><span class="lineNoCov">          0 :         error = &quot;ompi_osc_base_find_available() failed&quot;;</span>
<span class="lineNum">     635 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     636 </span>            :     }
<span class="lineNum">     637 </span>            : 
<span class="lineNum">     638 </span>            : #if OPAL_ENABLE_FT_CR == 1
<span class="lineNum">     639 </span>            :     if (OMPI_SUCCESS != (ret = ompi_crcp_base_select() ) ) {
<span class="lineNum">     640 </span>            :         error = &quot;ompi_crcp_base_select() failed&quot;;
<span class="lineNum">     641 </span>            :         goto error;
<span class="lineNum">     642 </span>            :     }
<span class="lineNum">     643 </span>            : #endif
<span class="lineNum">     644 </span>            : 
<span class="lineNum">     645 </span>            :     /* io and topo components are not selected here -- see comment
<span class="lineNum">     646 </span>            :        above about the io and topo frameworks being loaded lazily */
<span class="lineNum">     647 </span>            : 
<span class="lineNum">     648 </span>            :     /* Initialize each MPI handle subsystem */
<span class="lineNum">     649 </span>            :     /* initialize requests */
<span class="lineNum">     650 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_request_init())) {</span>
<span class="lineNum">     651 </span><span class="lineNoCov">          0 :         error = &quot;ompi_request_init() failed&quot;;</span>
<span class="lineNum">     652 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     653 </span>            :     }
<span class="lineNum">     654 </span>            : 
<span class="lineNum">     655 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_message_init())) {</span>
<span class="lineNum">     656 </span><span class="lineNoCov">          0 :         error = &quot;ompi_message_init() failed&quot;;</span>
<span class="lineNum">     657 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     658 </span>            :     }
<span class="lineNum">     659 </span>            : 
<span class="lineNum">     660 </span>            :     /* initialize info */
<span class="lineNum">     661 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_info_init())) {</span>
<span class="lineNum">     662 </span><span class="lineNoCov">          0 :         error = &quot;ompi_info_init() failed&quot;;</span>
<span class="lineNum">     663 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     664 </span>            :     }
<span class="lineNum">     665 </span>            : 
<span class="lineNum">     666 </span>            :     /* initialize error handlers */
<span class="lineNum">     667 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_errhandler_init())) {</span>
<span class="lineNum">     668 </span><span class="lineNoCov">          0 :         error = &quot;ompi_errhandler_init() failed&quot;;</span>
<span class="lineNum">     669 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     670 </span>            :     }
<span class="lineNum">     671 </span>            : 
<span class="lineNum">     672 </span>            :     /* initialize error codes */
<span class="lineNum">     673 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_mpi_errcode_init())) {</span>
<span class="lineNum">     674 </span><span class="lineNoCov">          0 :         error = &quot;ompi_mpi_errcode_init() failed&quot;;</span>
<span class="lineNum">     675 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     676 </span>            :     }
<span class="lineNum">     677 </span>            : 
<span class="lineNum">     678 </span>            :     /* initialize internal error codes */
<span class="lineNum">     679 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_errcode_intern_init())) {</span>
<span class="lineNum">     680 </span><span class="lineNoCov">          0 :         error = &quot;ompi_errcode_intern_init() failed&quot;;</span>
<span class="lineNum">     681 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     682 </span>            :     }
<span class="lineNum">     683 </span>            : 
<span class="lineNum">     684 </span>            :     /* initialize groups  */
<span class="lineNum">     685 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_group_init())) {</span>
<span class="lineNum">     686 </span><span class="lineNoCov">          0 :         error = &quot;ompi_group_init() failed&quot;;</span>
<span class="lineNum">     687 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     688 </span>            :     }
<span class="lineNum">     689 </span>            : 
<span class="lineNum">     690 </span>            :     /* initialize communicators */
<span class="lineNum">     691 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_comm_init())) {</span>
<span class="lineNum">     692 </span><span class="lineNoCov">          0 :         error = &quot;ompi_comm_init() failed&quot;;</span>
<span class="lineNum">     693 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     694 </span>            :     }
<span class="lineNum">     695 </span>            : 
<span class="lineNum">     696 </span>            :     /* initialize file handles */
<span class="lineNum">     697 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_file_init())) {</span>
<span class="lineNum">     698 </span><span class="lineNoCov">          0 :         error = &quot;ompi_file_init() failed&quot;;</span>
<span class="lineNum">     699 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     700 </span>            :     }
<span class="lineNum">     701 </span>            : 
<span class="lineNum">     702 </span>            :     /* initialize windows */
<span class="lineNum">     703 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_win_init())) {</span>
<span class="lineNum">     704 </span><span class="lineNoCov">          0 :         error = &quot;ompi_win_init() failed&quot;;</span>
<span class="lineNum">     705 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     706 </span>            :     }
<span class="lineNum">     707 </span>            : 
<span class="lineNum">     708 </span>            :     /* initialize attribute meta-data structure for comm/win/dtype */
<span class="lineNum">     709 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_attr_init())) {</span>
<span class="lineNum">     710 </span><span class="lineNoCov">          0 :         error = &quot;ompi_attr_init() failed&quot;;</span>
<span class="lineNum">     711 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     712 </span>            :     }
<span class="lineNum">     713 </span>            : 
<span class="lineNum">     714 </span>            :     /* identify the architectures of remote procs and setup
<span class="lineNum">     715 </span>            :      * their datatype convertors, if required
<span class="lineNum">     716 </span>            :      */
<span class="lineNum">     717 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_proc_complete_init())) {</span>
<span class="lineNum">     718 </span><span class="lineNoCov">          0 :         error = &quot;ompi_proc_complete_init failed&quot;;</span>
<span class="lineNum">     719 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     720 </span>            :     }
<span class="lineNum">     721 </span>            : 
<span class="lineNum">     722 </span>            :     /* start PML/BTL's */
<span class="lineNum">     723 </span><span class="lineCov">          2 :     ret = MCA_PML_CALL(enable(true));</span>
<span class="lineNum">     724 </span><span class="lineCov">          2 :     if( OMPI_SUCCESS != ret ) {</span>
<span class="lineNum">     725 </span><span class="lineNoCov">          0 :         error = &quot;PML control failed&quot;;</span>
<span class="lineNum">     726 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     727 </span>            :     }
<span class="lineNum">     728 </span>            : 
<span class="lineNum">     729 </span>            :     /* add all ompi_proc_t's to PML */
<span class="lineNum">     730 </span><span class="lineCov">          2 :     if (NULL == (procs = ompi_proc_world(&amp;nprocs))) {</span>
<span class="lineNum">     731 </span><span class="lineNoCov">          0 :         error = &quot;ompi_proc_world() failed&quot;;</span>
<span class="lineNum">     732 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     733 </span>            :     }
<span class="lineNum">     734 </span><span class="lineCov">          2 :     ret = MCA_PML_CALL(add_procs(procs, nprocs));</span>
<span class="lineNum">     735 </span><span class="lineCov">          2 :     free(procs);</span>
<span class="lineNum">     736 </span>            :     /* If we got &quot;unreachable&quot;, then print a specific error message.
<span class="lineNum">     737 </span>            :        Otherwise, if we got some other failure, fall through to print
<span class="lineNum">     738 </span>            :        a generic message. */
<span class="lineNum">     739 </span><span class="lineCov">          2 :     if (OMPI_ERR_UNREACH == ret) {</span>
<span class="lineNum">     740 </span><span class="lineNoCov">          0 :         opal_show_help(&quot;help-mpi-runtime.txt&quot;,</span>
<span class="lineNum">     741 </span>            :                        &quot;mpi_init:startup:pml-add-procs-fail&quot;, true);
<span class="lineNum">     742 </span><span class="lineNoCov">          0 :         error = NULL;</span>
<span class="lineNum">     743 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     744 </span><span class="lineCov">          2 :     } else if (OMPI_SUCCESS != ret) {</span>
<span class="lineNum">     745 </span><span class="lineNoCov">          0 :         error = &quot;PML add procs failed&quot;;</span>
<span class="lineNum">     746 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     747 </span>            :     }
<span class="lineNum">     748 </span>            : 
<span class="lineNum">     749 </span><span class="lineCov">          2 :     MCA_PML_CALL(add_comm(&amp;ompi_mpi_comm_world.comm));</span>
<span class="lineNum">     750 </span><span class="lineCov">          2 :     MCA_PML_CALL(add_comm(&amp;ompi_mpi_comm_self.comm));</span>
<span class="lineNum">     751 </span>            : 
<span class="lineNum">     752 </span>            :     /*
<span class="lineNum">     753 </span>            :      * Dump all MCA parameters if requested
<span class="lineNum">     754 </span>            :      */
<span class="lineNum">     755 </span><span class="lineCov">          2 :     if (ompi_mpi_show_mca_params) {</span>
<span class="lineNum">     756 </span><span class="lineNoCov">          0 :         ompi_show_all_mca_params(ompi_mpi_comm_world.comm.c_my_rank,</span>
<span class="lineNum">     757 </span>            :                                  nprocs,
<span class="lineNum">     758 </span>            :                                  ompi_process_info.nodename);
<span class="lineNum">     759 </span>            :     }
<span class="lineNum">     760 </span>            : 
<span class="lineNum">     761 </span>            :     /* Do we need to wait for a debugger? */
<span class="lineNum">     762 </span><span class="lineCov">          2 :     ompi_rte_wait_for_debugger();</span>
<span class="lineNum">     763 </span>            : 
<span class="lineNum">     764 </span>            :     /* Next timing measurement */
<span class="lineNum">     765 </span>            :     OPAL_TIMING_MNEXT((&amp;tm,&quot;time to execute barrier&quot;));
<span class="lineNum">     766 </span>            : 
<span class="lineNum">     767 </span>            :     /* wait for everyone to reach this point - this is a hard
<span class="lineNum">     768 </span>            :      * barrier requirement at this time, though we hope to relax
<span class="lineNum">     769 </span>            :      * it at a later point */
<span class="lineNum">     770 </span><span class="lineCov">          2 :     opal_pmix.fence(NULL, 0);</span>
<span class="lineNum">     771 </span>            : 
<span class="lineNum">     772 </span>            :     /* check for timing request - get stop time and report elapsed
<span class="lineNum">     773 </span>            :        time if so, then start the clock again */
<span class="lineNum">     774 </span>            :     OPAL_TIMING_MNEXT((&amp;tm,&quot;time from barrier to complete mpi_init&quot;));
<span class="lineNum">     775 </span>            : 
<span class="lineNum">     776 </span>            : #if OPAL_ENABLE_PROGRESS_THREADS == 0
<span class="lineNum">     777 </span>            :     /* Start setting up the event engine for MPI operations.  Don't
<span class="lineNum">     778 </span>            :        block in the event library, so that communications don't take
<span class="lineNum">     779 </span>            :        forever between procs in the dynamic code.  This will increase
<span class="lineNum">     780 </span>            :        CPU utilization for the remainder of MPI_INIT when we are
<span class="lineNum">     781 </span>            :        blocking on RTE-level events, but may greatly reduce non-TCP
<span class="lineNum">     782 </span>            :        latency. */
<span class="lineNum">     783 </span><span class="lineCov">          2 :     opal_progress_set_event_flag(OPAL_EVLOOP_NONBLOCK);</span>
<span class="lineNum">     784 </span>            : #endif
<span class="lineNum">     785 </span>            : 
<span class="lineNum">     786 </span>            :     /* wire up the mpi interface, if requested.  Do this after the
<span class="lineNum">     787 </span>            :        non-block switch for non-TCP performance.  Do before the
<span class="lineNum">     788 </span>            :        polling change as anyone with a complex wire-up is going to be
<span class="lineNum">     789 </span>            :        using the oob. */
<span class="lineNum">     790 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_init_preconnect_mpi())) {</span>
<span class="lineNum">     791 </span><span class="lineNoCov">          0 :         error = &quot;ompi_mpi_do_preconnect_all() failed&quot;;</span>
<span class="lineNum">     792 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     793 </span>            :     }
<span class="lineNum">     794 </span>            : 
<span class="lineNum">     795 </span>            :     /* Setup the publish/subscribe (PUBSUB) framework */
<span class="lineNum">     796 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_pubsub_base_framework, 0))) {</span>
<span class="lineNum">     797 </span><span class="lineNoCov">          0 :         error = &quot;mca_pubsub_base_open() failed&quot;;</span>
<span class="lineNum">     798 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     799 </span>            :     }
<span class="lineNum">     800 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_pubsub_base_select())) {</span>
<span class="lineNum">     801 </span><span class="lineNoCov">          0 :         error = &quot;ompi_pubsub_base_select() failed&quot;;</span>
<span class="lineNum">     802 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     803 </span>            :     }
<span class="lineNum">     804 </span>            : 
<span class="lineNum">     805 </span>            :     /* Setup the dynamic process management (DPM) framework */
<span class="lineNum">     806 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = mca_base_framework_open(&amp;ompi_dpm_base_framework, 0))) {</span>
<span class="lineNum">     807 </span><span class="lineNoCov">          0 :         error = &quot;ompi_dpm_base_open() failed&quot;;</span>
<span class="lineNum">     808 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     809 </span>            :     }
<span class="lineNum">     810 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_dpm_base_select())) {</span>
<span class="lineNum">     811 </span><span class="lineNoCov">          0 :         error = &quot;ompi_dpm_base_select() failed&quot;;</span>
<span class="lineNum">     812 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     813 </span>            :     }
<span class="lineNum">     814 </span>            : 
<span class="lineNum">     815 </span>            :     /* Determine the overall threadlevel support of all processes
<span class="lineNum">     816 </span>            :        in MPI_COMM_WORLD. This has to be done before calling
<span class="lineNum">     817 </span>            :        coll_base_comm_select, since some of the collective components
<span class="lineNum">     818 </span>            :        e.g. hierarch, might create subcommunicators. The threadlevel
<span class="lineNum">     819 </span>            :        requested by all processes is required in order to know
<span class="lineNum">     820 </span>            :        which cid allocation algorithm can be used. */
<span class="lineNum">     821 </span><span class="lineCov">          2 :     if ( OMPI_SUCCESS !=</span>
<span class="lineNum">     822 </span>            :          ( ret = ompi_comm_cid_init ())) {
<span class="lineNum">     823 </span><span class="lineNoCov">          0 :         error = &quot;ompi_mpi_init: ompi_comm_cid_init failed&quot;;</span>
<span class="lineNum">     824 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     825 </span>            :     }
<span class="lineNum">     826 </span>            : 
<span class="lineNum">     827 </span>            :     /* Init coll for the comms. This has to be after dpm_base_select,
<span class="lineNum">     828 </span>            :        (since dpm.mark_dyncomm is not set in the communicator creation
<span class="lineNum">     829 </span>            :        function else), but before dpm.dyncom_init, since this function
<span class="lineNum">     830 </span>            :        might require collective for the CID allocation. */
<span class="lineNum">     831 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS !=</span>
<span class="lineNum">     832 </span>            :         (ret = mca_coll_base_comm_select(MPI_COMM_WORLD))) {
<span class="lineNum">     833 </span><span class="lineNoCov">          0 :         error = &quot;mca_coll_base_comm_select(MPI_COMM_WORLD) failed&quot;;</span>
<span class="lineNum">     834 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     835 </span>            :     }
<span class="lineNum">     836 </span>            : 
<span class="lineNum">     837 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS !=</span>
<span class="lineNum">     838 </span>            :         (ret = mca_coll_base_comm_select(MPI_COMM_SELF))) {
<span class="lineNum">     839 </span><span class="lineNoCov">          0 :         error = &quot;mca_coll_base_comm_select(MPI_COMM_SELF) failed&quot;;</span>
<span class="lineNum">     840 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     841 </span>            :     }
<span class="lineNum">     842 </span>            : 
<span class="lineNum">     843 </span>            :     /* Check whether we have been spawned or not.  We introduce that
<span class="lineNum">     844 </span>            :        at the very end, since we need collectives, datatypes, ptls
<span class="lineNum">     845 </span>            :        etc. up and running here.... */
<span class="lineNum">     846 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_dpm.dyn_init())) {</span>
<span class="lineNum">     847 </span><span class="lineNoCov">          0 :         error = &quot;ompi_comm_dyn_init() failed&quot;;</span>
<span class="lineNum">     848 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     849 </span>            :     }
<span class="lineNum">     850 </span>            : 
<span class="lineNum">     851 </span>            :     /*
<span class="lineNum">     852 </span>            :      * Startup the Checkpoint/Restart Mech.
<span class="lineNum">     853 </span>            :      * Note: Always do this so tools don't hang when
<span class="lineNum">     854 </span>            :      * in a non-checkpointable build
<span class="lineNum">     855 </span>            :      */
<span class="lineNum">     856 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_cr_init())) {</span>
<span class="lineNum">     857 </span><span class="lineNoCov">          0 :         error = &quot;ompi_cr_init&quot;;</span>
<span class="lineNum">     858 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     859 </span>            :     }
<span class="lineNum">     860 </span>            : 
<span class="lineNum">     861 </span>            :     /* Undo OPAL calling opal_progress_event_users_increment() during
<span class="lineNum">     862 </span>            :        opal_init, to get better latency when not using TCP.  Do
<span class="lineNum">     863 </span>            :        this *after* dyn_init, as dyn init uses lots of RTE
<span class="lineNum">     864 </span>            :        communication and we don't want to hinder the performance of
<span class="lineNum">     865 </span>            :        that code. */
<span class="lineNum">     866 </span><span class="lineCov">          2 :     opal_progress_event_users_decrement();</span>
<span class="lineNum">     867 </span>            : 
<span class="lineNum">     868 </span>            :     /* see if yield_when_idle was specified - if so, use it */
<span class="lineNum">     869 </span><span class="lineCov">          2 :     opal_progress_set_yield_when_idle(ompi_mpi_yield_when_idle);</span>
<span class="lineNum">     870 </span>            : 
<span class="lineNum">     871 </span>            :     /* negative value means use default - just don't do anything */
<span class="lineNum">     872 </span><span class="lineCov">          2 :     if (ompi_mpi_event_tick_rate &gt;= 0) {</span>
<span class="lineNum">     873 </span><span class="lineNoCov">          0 :         opal_progress_set_event_poll_rate(ompi_mpi_event_tick_rate);</span>
<span class="lineNum">     874 </span>            :     }
<span class="lineNum">     875 </span>            : 
<span class="lineNum">     876 </span>            :     /* At this point, we are fully configured and in MPI mode.  Any
<span class="lineNum">     877 </span>            :        communication calls here will work exactly like they would in
<span class="lineNum">     878 </span>            :        the user's code.  Setup the connections between procs and warm
<span class="lineNum">     879 </span>            :        them up with simple sends, if requested */
<span class="lineNum">     880 </span>            : 
<span class="lineNum">     881 </span><span class="lineCov">          2 :     if (OMPI_SUCCESS != (ret = ompi_mpiext_init())) {</span>
<span class="lineNum">     882 </span><span class="lineNoCov">          0 :         error = &quot;ompi_mpiext_init&quot;;</span>
<span class="lineNum">     883 </span><span class="lineNoCov">          0 :         goto error;</span>
<span class="lineNum">     884 </span>            :     }
<span class="lineNum">     885 </span>            : 
<span class="lineNum">     886 </span>            :     /* Fall through */
<span class="lineNum">     887 </span>            :  error:
<span class="lineNum">     888 </span><span class="lineCov">          2 :     if (ret != OMPI_SUCCESS) {</span>
<span class="lineNum">     889 </span>            :         /* Only print a message if one was not already printed */
<span class="lineNum">     890 </span><span class="lineNoCov">          0 :         if (NULL != error) {</span>
<span class="lineNum">     891 </span><span class="lineNoCov">          0 :             const char *err_msg = opal_strerror(ret);</span>
<span class="lineNum">     892 </span><span class="lineNoCov">          0 :             opal_show_help(&quot;help-mpi-runtime.txt&quot;,</span>
<span class="lineNum">     893 </span>            :                            &quot;mpi_init:startup:internal-failure&quot;, true,
<span class="lineNum">     894 </span>            :                            &quot;MPI_INIT&quot;, &quot;MPI_INIT&quot;, error, err_msg, ret);
<span class="lineNum">     895 </span>            :         }
<span class="lineNum">     896 </span><span class="lineNoCov">          0 :         return ret;</span>
<span class="lineNum">     897 </span>            :     }
<span class="lineNum">     898 </span>            : 
<span class="lineNum">     899 </span>            :     /* Initialize the registered datarep list to be empty */
<span class="lineNum">     900 </span><span class="lineCov">          2 :     OBJ_CONSTRUCT(&amp;ompi_registered_datareps, opal_list_t);</span>
<span class="lineNum">     901 </span>            : 
<span class="lineNum">     902 </span>            :     /* Initialize the arrays used to store the F90 types returned by the
<span class="lineNum">     903 </span>            :      *  MPI_Type_create_f90_XXX functions.
<span class="lineNum">     904 </span>            :      */
<span class="lineNum">     905 </span><span class="lineCov">          2 :     OBJ_CONSTRUCT( &amp;ompi_mpi_f90_integer_hashtable, opal_hash_table_t);</span>
<span class="lineNum">     906 </span><span class="lineCov">          2 :     opal_hash_table_init(&amp;ompi_mpi_f90_integer_hashtable, 16 /* why not? */);</span>
<span class="lineNum">     907 </span>            : 
<span class="lineNum">     908 </span><span class="lineCov">          2 :     OBJ_CONSTRUCT( &amp;ompi_mpi_f90_real_hashtable, opal_hash_table_t);</span>
<span class="lineNum">     909 </span><span class="lineCov">          2 :     opal_hash_table_init(&amp;ompi_mpi_f90_real_hashtable, FLT_MAX_10_EXP);</span>
<span class="lineNum">     910 </span>            : 
<span class="lineNum">     911 </span><span class="lineCov">          2 :     OBJ_CONSTRUCT( &amp;ompi_mpi_f90_complex_hashtable, opal_hash_table_t);</span>
<span class="lineNum">     912 </span><span class="lineCov">          2 :     opal_hash_table_init(&amp;ompi_mpi_f90_complex_hashtable, FLT_MAX_10_EXP);</span>
<span class="lineNum">     913 </span>            : 
<span class="lineNum">     914 </span>            :     /* All done.  Wasn't that simple? */
<span class="lineNum">     915 </span>            : 
<span class="lineNum">     916 </span><span class="lineCov">          2 :     ompi_mpi_initialized = true;</span>
<span class="lineNum">     917 </span>            : 
<span class="lineNum">     918 </span>            :     /* Finish last measurement, output results
<span class="lineNum">     919 </span>            :      * and clear timing structure */
<span class="lineNum">     920 </span>            :     OPAL_TIMING_MSTOP(&amp;tm);
<span class="lineNum">     921 </span>            :     OPAL_TIMING_DELTAS(ompi_enable_timing, &amp;tm);
<span class="lineNum">     922 </span>            :     OPAL_TIMING_REPORT(ompi_enable_timing_ext, &amp;tm);
<span class="lineNum">     923 </span>            :     OPAL_TIMING_RELEASE(&amp;tm);
<span class="lineNum">     924 </span>            : 
<span class="lineNum">     925 </span><span class="lineCov">          2 :     return MPI_SUCCESS;</span>
<span class="lineNum">     926 </span>            : }
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.11</a></td></tr>
  </table>
  <br>

</body>
</html>
